{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719883da",
   "metadata": {},
   "source": [
    "### Predictive analysis tasks\n",
    "\n",
    "\n",
    "1. Prepare predictive model(s) of default. Default client is defined as one with loan_status variable taking on the following levels:\n",
    " \n",
    " \n",
    "* Charged off\n",
    "* Default\n",
    "* Does not meet the credit policy. Status: Charged Off\n",
    "* Late (31-120 days)\n",
    " \n",
    " \n",
    "2. Present a few competing predictive models and select one of them. Explain criteria for the selection\n",
    "\n",
    "\n",
    "3. Please provide confusion matrix or ROC/AUC curve\n",
    "\n",
    "\n",
    "4. Optionally, calculate performance metrics you find important in this specific context (metrics should be based on testing set, which should consist 30% randomly selected clients from the original dataset)\n",
    "\n",
    "\n",
    "5. If necessary, make appropriate data pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have any library or module you can download by using following method (pip):\n",
    "# !pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "539e4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "#Display options\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None  \n",
    "pd.options.display.max_rows = 999\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513b4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reading \n",
    "data = pd.read_csv('lending_club_loans.csv',encoding=\"latin1\", header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f03db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64655643",
   "metadata": {},
   "source": [
    "### Data Preparation (20 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping columns with only missing data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf102b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only rows, which in given columns do not have missing values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted text, changing the type of variables (mainly string into float/ integer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46394f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new variable for those with employment title, having title=1, otherwise=0, too many categories for dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db94e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the distribution of a target variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our target variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9198c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating two independent variables: year and month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc366e87",
   "metadata": {},
   "source": [
    "### Dummy variable creation (10 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cb172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating dummies from categorical var:\n",
    "\n",
    "#changing few columns names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e01e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of variables to drop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving just in case preprocessed data are needed -in csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2fa9f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install imblearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing esential modules:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, StratifiedKFold \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, classification_report, roc_curve, roc_auc_score\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "from imblearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432af8c",
   "metadata": {},
   "source": [
    "### 10 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dee76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating target and explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/ testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the target variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb21592",
   "metadata": {},
   "source": [
    "### Pipelines or building model(s)(30 min. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines for models (OPTIONAL):\n",
    " \n",
    "# 1.We use: Synthetic Minority Oversampling Technique (SMOTE):#each class will be synthesized with the centroids\n",
    "# of the K-means method instead of the original samples:\n",
    "#2. Scaler for those methods where it is needed\n",
    "#3. Models: trying Logistic Regression, Decision Tree, XGB, Random Forest, and KNN Clasificators, due to large sample size SVC is too time consuming\n",
    "#4. Searching for the best parameters by cross validation, scoring matric= roc_auc\n",
    "#5. Saving the best estimator in list, and the results (Summary results only) of output in 'Grid_search_1.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e369a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Comparison of different measures of accuracy for the best parameters in our models:\n",
    "# 2.Saving results (Summary results only) in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d732d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Result of cross- validation based on the different scoring: on cohen_kappa_score, better suited for imbalanced data\n",
    "#2. Results (Summary results only) saved in  'Grid_search_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Comparison of different measures of accuracy for the best parameters in our models:\n",
    "# 2.Saving results (Summary results only) in a file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0e7be",
   "metadata": {},
   "source": [
    "### Model selection (20 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Comparison of different measures of accuracy for the best parameters in our models:\n",
    "# 2.Saving results (Summary results only) in a file \n",
    "# 3. As we are interested in predicting those not abble to pay a loan, it seems that the most important accuracy measure is Recall = TP/(TP+FN):\n",
    "# 4. Due to the imbalacing of the data - only 15% of positive outcome, many observations could be predicted as False Negatives, meaning\n",
    "# that we predict a fully paid loan, but it is in fact charged off, based on the comaprison of this accuracy measure between models, \n",
    "# the first one: Logistic regression seems to be the best suited to the problem, and the second tuning of paramters using kappa score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ce19c",
   "metadata": {},
   "source": [
    "### Graphical presentation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# Graph of the ROC curve  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# As we decided to chose logistic regression due to the best accuracy to the problem, \n",
    "# we could look a little closer to the largest features for the prediction (scaled before the regression), presented at the graph \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d159ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
